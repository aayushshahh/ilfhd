# -*- coding: utf-8 -*-
"""sign.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XTXUuk6iyqu5jQxh4YHhaUSj9fGJp_kV
"""

import pandas as pd
from sklearn.model_selection import train_test_split
import string
from string import digits
import re
from sklearn.utils import shuffle
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed
from tensorflow.keras.models import Model,load_model, model_from_json
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing.text import one_hot, Tokenizer
from tensorflow.keras.callbacks import EarlyStopping
import pickle as pkl
import numpy as np


# loading the model architecture and asigning the weights
json_file = open('NMT_model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
model_loaded = model_from_json(loaded_model_json)
# load weights into new model
model_loaded.load_weights("NMT_model_weight.h5")

with open('NMT_Etokenizer.pkl','rb') as f:
  vocab_size_source, Eword2index, englishTokenizer = pkl.load(f)


with open('NMT_data.pkl','rb') as f:
  X_train, y_train, X_test, y_test = pkl.load(f)

Eindex2word = englishTokenizer.index_word

latent_dim=500
# encoder inference
encoder_inputs = model_loaded.input[0]  #loading encoder_inputs
encoder_outputs, state_h, state_c = model_loaded.layers[5].output #loading encoder_outputs


encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])

decoder_state_input_h = Input(shape=(latent_dim,))
decoder_state_input_c = Input(shape=(latent_dim,))
decoder_hidden_state_input = Input(shape=(7,latent_dim))

decoder_inputs = model_loaded.layers[2].output

dec_emb_layer = model_loaded.layers[4]

dec_emb2= dec_emb_layer(decoder_inputs)

decoder_lstm = model_loaded.layers[6]
decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])


decoder_dense = model_loaded.layers[7]
decoder_outputs2 = decoder_dense(decoder_outputs2)

decoder_states_inputs = [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c]
decoder_states = [state_h2, state_c2]


decoder_model = Model(
[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],
[decoder_outputs2] + decoder_states)



def decode_sequence(input_seq):
    e_out, e_h, e_c = encoder_model.predict(input_seq)

    target_seq = np.zeros((1,1))

    target_seq[0, 0] = Eword2index['start']

    stop_condition = False
    decoded_sentence = ''
    while not stop_condition:
        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])

        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        if sampled_token_index == 0:
          break
        else:
          sampled_token = Eindex2word[sampled_token_index]

          if(sampled_token!='end'):
              decoded_sentence += ' '+sampled_token

              if (sampled_token == 'end' or len(decoded_sentence.split()) >= (26-1)):
                  stop_condition = True

          target_seq = np.zeros((1,1))
          target_seq[0, 0] = sampled_token_index

          e_h, e_c = h, c

    return decoded_sentence

def seq2summary(input_seq):
    newString=''
    for i in input_seq:
      if((i!=0 and i!=Eword2index['start']) and i!=Eword2index['end']):
        newString=newString+Eindex2word[i]+' '
    return newString

def seq2text(input_seq):
    newString=''
    for i in input_seq:
      if(i!=0):
        newString=newString+Eindex2word[i]+' '
    return newString

def word2no(input):
    newString=[]
    res = input.split()
    for i in res:
      if(i!=0):
        word_no = Eword2index[i]
        newString.append(word_no)
    return newString




index_output = word2no("tom is very serious")
numbersList = []
numbersList.append(index_output)
second = []
numbersList.append(second)
index_output_1 = pad_sequences(numbersList, maxlen=7, padding='post')
print("Predicted summary:",decode_sequence(index_output_1[0].reshape(1,7)))

